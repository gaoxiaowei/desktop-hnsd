From 9b7b0ed34452d12e302a5c55260a81a4ddfea7c8 Mon Sep 17 00:00:00 2001
From: Jonathon Hall <jhall@londontrustmedia.com>
Date: Wed, 8 May 2019 16:38:42 -0400
Subject: [PATCH 05/12] Use a worker thread to run libunbound's results queue

---
 src/rs.c | 264 ++++++++++++++++++++++++++++++++++++++++++++++++-------
 src/rs.h |  21 ++++-
 2 files changed, 251 insertions(+), 34 deletions(-)

diff --git a/src/rs.c b/src/rs.c
index 532b568..9d28f6a 100644
--- a/src/rs.c
+++ b/src/rs.c
@@ -64,15 +64,114 @@ after_recv(
   unsigned flags
 );
 
+// Resolve callback on libunbound worker thread.
 static void
-after_poll(uv_poll_t *handle, int status, int events);
+after_resolve_onthread(void *data, int status, struct ub_result *result);
 
+// Resolve async event handler in libuv event loop.
 static void
-after_resolve(void *data, int status, struct ub_result *result);
+after_resolve(uv_async_t *async);
 
 static void
 after_close(uv_handle_t *handle);
 
+static void
+after_close_free(uv_handle_t *handle);
+
+static void
+run_unbound_worker(void *arg);
+
+static void
+after_resolve_shutdown(void *data, int status, struct ub_result *result);
+
+/*
+ * Response Queue
+ */
+int
+hsk_rs_queue_init(hsk_rs_queue_t *queue) {
+  if (uv_mutex_init(&queue->mutex))
+    return HSK_EFAILURE;
+  queue->head = NULL;
+  queue->tail = NULL;
+
+  return HSK_SUCCESS;
+}
+
+void
+hsk_rs_queue_uninit(hsk_rs_queue_t *queue) {
+  hsk_rs_rsp_t *current = queue->head;
+  while (current) {
+    hsk_rs_rsp_t *next = current->next;
+    free(current);
+    current = next;
+  }
+
+  uv_mutex_destroy(&queue->mutex);
+}
+
+hsk_rs_queue_t *hsk_rs_queue_alloc() {
+  hsk_rs_queue_t *queue = malloc(sizeof(hsk_rs_queue_t));
+  if(!queue)
+    return NULL;
+
+  if (hsk_rs_queue_init(queue) != HSK_SUCCESS) {
+    free(queue);
+    return NULL;
+  }
+
+  return queue;
+}
+
+void hsk_rs_queue_free(hsk_rs_queue_t *queue) {
+  if(!queue)
+    return;
+
+  hsk_rs_queue_uninit(queue);
+  free(queue);
+}
+
+// Dequeue the oldest queued response - thread-safe.
+// Returned object is now owned by the caller; returns nullptr if there is
+// nothing queued.
+hsk_rs_rsp_t *
+hsk_rs_queue_dequeue(hsk_rs_queue_t *queue) {
+  uv_mutex_lock(&queue->mutex);
+
+  hsk_rs_rsp_t *oldest = queue->head;
+  if (oldest) {
+    queue->head = oldest->next;
+    oldest->next = NULL;
+    // If this was the only queued request, clear tail too
+    if(queue->tail == oldest)
+      queue->tail = NULL;
+  }
+
+  uv_mutex_unlock(&queue->mutex);
+
+  return oldest;
+}
+
+// Enqueue a response - thread-safe.
+// The queue takes ownership of the response (until it's popped off again).
+void
+hsk_rs_queue_enqueue(hsk_rs_queue_t *queue, hsk_rs_rsp_t *rsp) {
+  uv_mutex_lock(&queue->mutex);
+
+  if (!queue->tail) {
+    // There were no requests queued; this one becomes head and tail
+    assert(!queue->head);   // Invariant - set and cleared together
+    queue->head = rsp;
+    queue->tail = rsp;
+  }
+  else {
+    // There are requests queued already, add this one to the tail
+    queue->tail->next = rsp;
+    queue->tail = rsp;
+  }
+
+  uv_mutex_unlock(&queue->mutex);
+}
+
 /*
  * Recursive NS
  */
@@ -85,6 +184,8 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   int err = HSK_ENOMEM;
   struct ub_ctx *ub = NULL;
   hsk_ec_t *ec = NULL;
+  hsk_rs_queue_t *rs_queue = NULL;
+  uv_async_t *rs_async = NULL;
 
   ub = ub_ctx_create();
 
@@ -94,6 +195,16 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   if (ub_ctx_async(ub, 1) != 0)
     goto fail;
 
+  rs_queue = hsk_rs_queue_alloc();
+
+  if (!rs_queue)
+    goto fail;
+
+  // Allocate this separately on the heap because uv_close() is asynchronous.
+  rs_async = malloc(sizeof(uv_async_t));
+  if (!rs_async || uv_async_init((uv_loop_t*)loop, rs_async, after_resolve))
+    goto fail;
+
   ec = hsk_ec_alloc();
 
   if (!ec)
@@ -102,7 +213,9 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   ns->loop = (uv_loop_t *)loop;
   ns->ub = ub;
   ns->socket.data = (void *)ns;
-  ns->poll.data = (void *)ns;
+  ns->rs_queue = rs_queue;
+  ns->rs_async = rs_async;
+  ns->rs_async->data = (void *)ns;
   ns->ec = ec;
   ns->config = NULL;
   ns->stub = (struct sockaddr *)&ns->stub_;
@@ -113,7 +226,7 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   memset(ns->read_buffer, 0x00, sizeof(ns->read_buffer));
   ns->bound = false;
   ns->receiving = false;
-  ns->polling = false;
+  ns->rs_worker_running = false;
 
   if (stub) {
     err = HSK_EFAILURE;
@@ -131,6 +244,12 @@ fail:
   if (ub)
     ub_ctx_delete(ub);
 
+  if (rs_queue)
+    hsk_rs_queue_free(rs_queue);
+
+  if (rs_async)
+    free(rs_async);
+
   if (ec)
     hsk_ec_free(ec);
 
@@ -143,7 +262,6 @@ hsk_rs_uninit(hsk_rs_t *ns) {
     return;
 
   ns->socket.data = NULL;
-  ns->poll.data = NULL;
 
   if (ns->ec) {
     hsk_ec_free(ns->ec);
@@ -155,6 +273,21 @@ hsk_rs_uninit(hsk_rs_t *ns) {
     ns->ub = NULL;
   }
 
+  // Free the response event and queue after destroying the unbound context.
+  // The libunbound worker has now stopped, so we can safely free these.
+  if (ns->rs_async) {
+    ns->rs_async->data = NULL;
+    // We have to free this object in the callback, libuv specifically says it
+    // must not be freed before the callback occurs
+    uv_close((uv_handle_t *)ns->rs_async, after_close_free);
+    ns->rs_async = NULL;
+  }
+
+  if (ns->rs_queue) {
+    hsk_rs_queue_free(ns->rs_queue);
+    ns->rs_queue = NULL;
+  }
+
   if (ns->config) {
     free(ns->config);
     ns->config = NULL;
@@ -246,6 +379,10 @@ hsk_rs_inject_options(hsk_rs_t *ns) {
     return false;
   }
 
+  // Use a thread instead of forking for libunbound's async work.  Threads work
+  // on all platforms, but forking does not work on Windows.
+  ub_ctx_async(ns->ub, 1);
+
   hsk_rs_log(ns, "recursive nameserver pointing to: %s\n", stub);
 
   return true;
@@ -282,14 +419,11 @@ hsk_rs_open(hsk_rs_t *ns, const struct sockaddr *addr) {
 
   ns->receiving = true;
 
-  if (uv_poll_init(ns->loop, &ns->poll, ub_fd(ns->ub)) != 0)
-    return HSK_EFAILURE;
-
-  ns->polling = true;
-  ns->poll.data = (void *)ns;
-
-  if (uv_poll_start(&ns->poll, UV_READABLE, after_poll) != 0)
+  ns->rs_worker_running = true;
+  if (uv_thread_create(&ns->rs_worker, run_unbound_worker, (void *)ns) != 0) {
+    ns->rs_worker_running = false;
     return HSK_EFAILURE;
+  }
 
   char host[HSK_MAX_HOST];
   assert(hsk_sa_to_string(addr, host, HSK_MAX_HOST, HSK_NS_PORT));
@@ -304,6 +438,25 @@ hsk_rs_close(hsk_rs_t *ns) {
   if (!ns)
     return HSK_EBADARGS;
 
+  if (ns->rs_worker_running) {
+    // We need to tell the libunbound worker to exit - wake up the thread and
+    // clear rs_worker_running on that thread.
+    //
+    // libunbound doesn't give us a good way to do this, the only way is to
+    // issue a dummy query and do this in the callback on the worker thread.
+    //
+    // On Unix, we could poll unbound's file descriptor manually with another
+    // file descriptor to allow us to wake the thread here.  On Windows though,
+    // libunbound does not provide any access to its WSAEVENT to do the same
+    // thing.
+    int rc = ub_resolve_async(ns->ub, ".", HSK_DNS_NS, HSK_DNS_IN, (void *)ns,
+                              after_resolve_shutdown, NULL);
+    if(rc != 0)
+      hsk_rs_log(ns, "cannot shut down worker thread: %s\n", ub_strerror(rc));
+    else
+      uv_thread_join(&ns->rs_worker);
+  }
+
   if (ns->receiving) {
     if (uv_udp_recv_stop(&ns->socket) != 0)
       return HSK_EFAILURE;
@@ -315,14 +468,7 @@ hsk_rs_close(hsk_rs_t *ns) {
     ns->bound = false;
   }
 
-  if (ns->polling) {
-    if (uv_poll_stop(&ns->poll) != 0)
-      return HSK_EFAILURE;
-    ns->polling = false;
-  }
-
   ns->socket.data = NULL;
-  ns->poll.data = NULL;
 
   if (ns->ub) {
     ub_ctx_delete(ns->ub);
@@ -416,7 +562,7 @@ hsk_rs_onrecv(
     req->type,
     req->class,
     (void *)req,
-    after_resolve,
+    after_resolve_onthread,
     NULL
   );
 
@@ -668,28 +814,82 @@ after_recv(
   );
 }
 
+// Handle a resolve result and respond to a DNS query for the recursive
+// resolver - called on the libunbound worker thread
 static void
-after_poll(uv_poll_t *handle, int status, int events) {
-  hsk_rs_t *ns = (hsk_rs_t *)handle->data;
+after_resolve_onthread(void *data, int status, struct ub_result *result) {
+  hsk_dns_req_t *req = (hsk_dns_req_t *)data;
+  // We can safely get the nameserver object from the request; the main thread
+  // does not use it after ub_resolve_async() succeeds (ownership is passed to
+  // this callback).
+  hsk_rs_t *ns = (hsk_rs_t *)req->ns;
 
-  if (!ns)
+  hsk_rs_rsp_t *rsp = malloc(sizeof(hsk_rs_rsp_t));
+  if(!rsp)
     return;
 
-  if (status == 0 && (events & UV_READABLE))
-    ub_process(ns->ub);
+  rsp->next = NULL;
+  rsp->req = req;
+  rsp->result = result;
+  rsp->status = status;
+
+  // Enqueue the response.  This is safe to do on the worker thread:
+  // - The ns->rs_queue pointer is not modified after initialization until the
+  //   worker thread has been stopped
+  // - The hsk_rs_queue_t object itself is thread-safe
+  hsk_rs_queue_enqueue(ns->rs_queue, rsp);
+
+  // Queue an async event to process the response on the libuv event loop.
+  // Like rs_queue, the rs_async pointer is safe to use because it's not
+  // modified until the libunbound worker is stopped.
+  uv_async_send(ns->rs_async);
 }
 
 static void
-after_resolve(void *data, int status, struct ub_result *result) {
-  hsk_dns_req_t *req = (hsk_dns_req_t *)data;
-  hsk_rs_t *ns = (hsk_rs_t *)req->ns;
+after_resolve(uv_async_t *async) {
+  hsk_rs_t *ns = (hsk_rs_t *)async->data;
 
-  assert(ns);
+  // Since uv_close() is async, it might be possible to process this event after
+  // the NS is shut down but before the async is closed.
+  if(!ns)
+    return;
 
-  hsk_rs_respond(ns, req, status, result);
-  hsk_dns_req_free(req);
-  ub_resolve_free(result);
+  // Dequeue and process all events in the queue - libuv coalesces calls to
+  // uv_async_send().
+  hsk_rs_rsp_t *rsp = hsk_rs_queue_dequeue(ns->rs_queue);
+  while(rsp) {
+    hsk_rs_respond(ns, rsp->req, rsp->status, rsp->result);
+
+    hsk_dns_req_free(rsp->req);
+    ub_resolve_free(rsp->result);
+    free(rsp);
+
+    rsp = hsk_rs_queue_dequeue(ns->rs_queue);
+  }
 }
 
 static void
 after_close(uv_handle_t *handle) {}
+
+static void
+after_close_free(uv_handle_t *handle) {
+  free(handle);
+}
+
+static void
+run_unbound_worker(void *arg) {
+  hsk_rs_t *ns = (hsk_rs_t *)arg;
+
+  while(ns->rs_worker_running) {
+    ub_wait(ns->ub);
+  }
+}
+
+static void
+after_resolve_shutdown(void *data, int status, struct ub_result *result) {
+  ub_resolve_free(result);
+
+  hsk_rs_t *ns = (hsk_rs_t *)data;
+
+  ns->rs_worker_running = false;
+}
diff --git a/src/rs.h b/src/rs.h
index c2aac70..34128db 100644
--- a/src/rs.h
+++ b/src/rs.h
@@ -14,11 +14,28 @@
  * Types
  */
 
+// Response data from libunbound - used to queue responses back to the libuv
+// event loop in a linked list
+typedef struct _hsk_rs_rsp_t {
+  struct _hsk_rs_rsp_t *next;
+  hsk_dns_req_t *req;
+  struct ub_result *result;
+  int status;
+} hsk_rs_rsp_t;
+
+typedef struct {
+  uv_mutex_t mutex;
+  hsk_rs_rsp_t *head;  // Oldest response
+  hsk_rs_rsp_t *tail;  // Newest response
+} hsk_rs_queue_t;
+
 typedef struct {
   uv_loop_t *loop;
   struct ub_ctx *ub;
   uv_udp_t socket;
-  uv_poll_t poll;
+  hsk_rs_queue_t *rs_queue;
+  uv_async_t *rs_async;
+  uv_thread_t rs_worker;
   hsk_ec_t *ec;
   char *config;
   struct sockaddr_storage stub_;
@@ -29,7 +46,7 @@ typedef struct {
   uint8_t read_buffer[4096];
   bool bound;
   bool receiving;
-  bool polling;
+  bool rs_worker_running;
 } hsk_rs_t;
 
 /*
-- 
2.17.1

