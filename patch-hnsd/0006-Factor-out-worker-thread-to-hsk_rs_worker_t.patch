From 28c2f817a4994251a57f767b9043104ce87d88fc Mon Sep 17 00:00:00 2001
From: Jonathon Hall <jhall@londontrustmedia.com>
Date: Thu, 9 May 2019 10:34:02 -0400
Subject: [PATCH 06/12] Factor out worker thread to hsk_rs_worker_t

---
 Makefile.am     |   3 +-
 src/rs.c        | 254 +++--------------------------------
 src/rs.h        |  21 +--
 src/rs_worker.c | 347 ++++++++++++++++++++++++++++++++++++++++++++++++
 src/rs_worker.h |  84 ++++++++++++
 5 files changed, 452 insertions(+), 257 deletions(-)
 create mode 100644 src/rs_worker.c
 create mode 100644 src/rs_worker.h

diff --git a/Makefile.am b/Makefile.am
index 6c2b65a..b820ba3 100644
--- a/Makefile.am
+++ b/Makefile.am
@@ -66,7 +66,8 @@ noinst_PROGRAMS = $(PROGS)
 hnsd_SOURCES = src/cache.c  \
                src/daemon.c \
                src/ns.c     \
-               src/rs.c
+               src/rs.c     \
+               src/rs_worker.c
 
 hnsd_LDADD = $(LIB_UNBOUND)             \
              $(top_builddir)/libhsk.la
diff --git a/src/rs.c b/src/rs.c
index 9d28f6a..44f290f 100644
--- a/src/rs.c
+++ b/src/rs.c
@@ -64,114 +64,12 @@ after_recv(
   unsigned flags
 );
 
-// Resolve callback on libunbound worker thread.
 static void
-after_resolve_onthread(void *data, int status, struct ub_result *result);
-
-// Resolve async event handler in libuv event loop.
-static void
-after_resolve(uv_async_t *async);
+after_resolve(void *data, int status, struct ub_result *result);
 
 static void
 after_close(uv_handle_t *handle);
 
-static void
-after_close_free(uv_handle_t *handle);
-
-static void
-run_unbound_worker(void *arg);
-
-static void
-after_resolve_shutdown(void *data, int status, struct ub_result *result);
-
-/*
- * Response Queue
- */
-int
-hsk_rs_queue_init(hsk_rs_queue_t *queue) {
-  if (uv_mutex_init(&queue->mutex))
-    return HSK_EFAILURE;
-  queue->head = NULL;
-  queue->tail = NULL;
-
-  return HSK_SUCCESS;
-}
-
-void
-hsk_rs_queue_uninit(hsk_rs_queue_t *queue) {
-  hsk_rs_rsp_t *current = queue->head;
-  while (current) {
-    hsk_rs_rsp_t *next = current->next;
-    free(current);
-    current = next;
-  }
-
-  uv_mutex_destroy(&queue->mutex);
-}
-
-hsk_rs_queue_t *hsk_rs_queue_alloc() {
-  hsk_rs_queue_t *queue = malloc(sizeof(hsk_rs_queue_t));
-  if(!queue)
-    return NULL;
-
-  if (hsk_rs_queue_init(queue) != HSK_SUCCESS) {
-    free(queue);
-    return NULL;
-  }
-
-  return queue;
-}
-
-void hsk_rs_queue_free(hsk_rs_queue_t *queue) {
-  if(!queue)
-    return;
-
-  hsk_rs_queue_uninit(queue);
-  free(queue);
-}
-
-// Dequeue the oldest queued response - thread-safe.
-// Returned object is now owned by the caller; returns nullptr if there is
-// nothing queued.
-hsk_rs_rsp_t *
-hsk_rs_queue_dequeue(hsk_rs_queue_t *queue) {
-  uv_mutex_lock(&queue->mutex);
-
-  hsk_rs_rsp_t *oldest = queue->head;
-  if (oldest) {
-    queue->head = oldest->next;
-    oldest->next = NULL;
-    // If this was the only queued request, clear tail too
-    if(queue->tail == oldest)
-      queue->tail = NULL;
-  }
-
-  uv_mutex_unlock(&queue->mutex);
-
-  return oldest;
-}
-
-// Enqueue a response - thread-safe.
-// The queue takes ownership of the response (until it's popped off again).
-void
-hsk_rs_queue_enqueue(hsk_rs_queue_t *queue, hsk_rs_rsp_t *rsp) {
-  uv_mutex_lock(&queue->mutex);
-
-  if (!queue->tail) {
-    // There were no requests queued; this one becomes head and tail
-    assert(!queue->head);   // Invariant - set and cleared together
-    queue->head = rsp;
-    queue->tail = rsp;
-  }
-  else {
-    // There are requests queued already, add this one to the tail
-    queue->tail->next = rsp;
-    queue->tail = rsp;
-  }
-
-  uv_mutex_unlock(&queue->mutex);
-}
-
 /*
  * Recursive NS
  */
@@ -184,8 +82,6 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   int err = HSK_ENOMEM;
   struct ub_ctx *ub = NULL;
   hsk_ec_t *ec = NULL;
-  hsk_rs_queue_t *rs_queue = NULL;
-  uv_async_t *rs_async = NULL;
 
   ub = ub_ctx_create();
 
@@ -195,16 +91,6 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   if (ub_ctx_async(ub, 1) != 0)
     goto fail;
 
-  rs_queue = hsk_rs_queue_alloc();
-
-  if (!rs_queue)
-    goto fail;
-
-  // Allocate this separately on the heap because uv_close() is asynchronous.
-  rs_async = malloc(sizeof(uv_async_t));
-  if (!rs_async || uv_async_init((uv_loop_t*)loop, rs_async, after_resolve))
-    goto fail;
-
   ec = hsk_ec_alloc();
 
   if (!ec)
@@ -213,9 +99,7 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   ns->loop = (uv_loop_t *)loop;
   ns->ub = ub;
   ns->socket.data = (void *)ns;
-  ns->rs_queue = rs_queue;
-  ns->rs_async = rs_async;
-  ns->rs_async->data = (void *)ns;
+  ns->rs_worker = NULL;
   ns->ec = ec;
   ns->config = NULL;
   ns->stub = (struct sockaddr *)&ns->stub_;
@@ -226,7 +110,6 @@ hsk_rs_init(hsk_rs_t *ns, const uv_loop_t *loop, const struct sockaddr *stub) {
   memset(ns->read_buffer, 0x00, sizeof(ns->read_buffer));
   ns->bound = false;
   ns->receiving = false;
-  ns->rs_worker_running = false;
 
   if (stub) {
     err = HSK_EFAILURE;
@@ -244,12 +127,6 @@ fail:
   if (ub)
     ub_ctx_delete(ub);
 
-  if (rs_queue)
-    hsk_rs_queue_free(rs_queue);
-
-  if (rs_async)
-    free(rs_async);
-
   if (ec)
     hsk_ec_free(ec);
 
@@ -273,21 +150,6 @@ hsk_rs_uninit(hsk_rs_t *ns) {
     ns->ub = NULL;
   }
 
-  // Free the response event and queue after destroying the unbound context.
-  // The libunbound worker has now stopped, so we can safely free these.
-  if (ns->rs_async) {
-    ns->rs_async->data = NULL;
-    // We have to free this object in the callback, libuv specifically says it
-    // must not be freed before the callback occurs
-    uv_close((uv_handle_t *)ns->rs_async, after_close_free);
-    ns->rs_async = NULL;
-  }
-
-  if (ns->rs_queue) {
-    hsk_rs_queue_free(ns->rs_queue);
-    ns->rs_queue = NULL;
-  }
-
   if (ns->config) {
     free(ns->config);
     ns->config = NULL;
@@ -419,11 +281,9 @@ hsk_rs_open(hsk_rs_t *ns, const struct sockaddr *addr) {
 
   ns->receiving = true;
 
-  ns->rs_worker_running = true;
-  if (uv_thread_create(&ns->rs_worker, run_unbound_worker, (void *)ns) != 0) {
-    ns->rs_worker_running = false;
+  ns->rs_worker = hsk_rs_worker_alloc(ns->loop, ns->ub);
+  if (!ns->rs_worker)
     return HSK_EFAILURE;
-  }
 
   char host[HSK_MAX_HOST];
   assert(hsk_sa_to_string(addr, host, HSK_MAX_HOST, HSK_NS_PORT));
@@ -438,23 +298,9 @@ hsk_rs_close(hsk_rs_t *ns) {
   if (!ns)
     return HSK_EBADARGS;
 
-  if (ns->rs_worker_running) {
-    // We need to tell the libunbound worker to exit - wake up the thread and
-    // clear rs_worker_running on that thread.
-    //
-    // libunbound doesn't give us a good way to do this, the only way is to
-    // issue a dummy query and do this in the callback on the worker thread.
-    //
-    // On Unix, we could poll unbound's file descriptor manually with another
-    // file descriptor to allow us to wake the thread here.  On Windows though,
-    // libunbound does not provide any access to its WSAEVENT to do the same
-    // thing.
-    int rc = ub_resolve_async(ns->ub, ".", HSK_DNS_NS, HSK_DNS_IN, (void *)ns,
-                              after_resolve_shutdown, NULL);
-    if(rc != 0)
-      hsk_rs_log(ns, "cannot shut down worker thread: %s\n", ub_strerror(rc));
-    else
-      uv_thread_join(&ns->rs_worker);
+  if (ns->rs_worker) {
+    hsk_rs_worker_free(ns->rs_worker);
+    ns->rs_worker = NULL;
   }
 
   if (ns->receiving) {
@@ -556,20 +402,19 @@ hsk_rs_onrecv(
     goto fail;
   }
 
-  rc = ub_resolve_async(
-    ns->ub,
+  rc = hsk_rs_worker_resolve(
+    ns->rs_worker,
     req->name,
     req->type,
     req->class,
     (void *)req,
-    after_resolve_onthread,
-    NULL
+    after_resolve
   );
 
-  if (rc == 0)
+  if (rc == HSK_SUCCESS)
     return;
 
-  hsk_rs_log(ns, "unbound error: %s\n", ub_strerror(rc));
+  hsk_rs_log(ns, "resolve error: %s\n", hsk_strerror(rc));
 
   msg = hsk_resource_to_servfail();
 
@@ -814,82 +659,17 @@ after_recv(
   );
 }
 
-// Handle a resolve result and respond to a DNS query for the recursive
-// resolver - called on the libunbound worker thread
 static void
-after_resolve_onthread(void *data, int status, struct ub_result *result) {
+after_resolve(void *data, int status, struct ub_result *result) {
   hsk_dns_req_t *req = (hsk_dns_req_t *)data;
-  // We can safely get the nameserver object from the request; the main thread
-  // does not use it after ub_resolve_async() succeeds (ownership is passed to
-  // this callback).
   hsk_rs_t *ns = (hsk_rs_t *)req->ns;
 
-  hsk_rs_rsp_t *rsp = malloc(sizeof(hsk_rs_rsp_t));
-  if(!rsp)
-    return;
-
-  rsp->next = NULL;
-  rsp->req = req;
-  rsp->result = result;
-  rsp->status = status;
-
-  // Enqueue the response.  This is safe to do on the worker thread:
-  // - The ns->rs_queue pointer is not modified after initialization until the
-  //   worker thread has been stopped
-  // - The hsk_rs_queue_t object itself is thread-safe
-  hsk_rs_queue_enqueue(ns->rs_queue, rsp);
-
-  // Queue an async event to process the response on the libuv event loop.
-  // Like rs_queue, the rs_async pointer is safe to use because it's not
-  // modified until the libunbound worker is stopped.
-  uv_async_send(ns->rs_async);
-}
-
-static void
-after_resolve(uv_async_t *async) {
-  hsk_rs_t *ns = (hsk_rs_t *)async->data;
-
-  // Since uv_close() is async, it might be possible to process this event after
-  // the NS is shut down but before the async is closed.
-  if(!ns)
-    return;
-
-  // Dequeue and process all events in the queue - libuv coalesces calls to
-  // uv_async_send().
-  hsk_rs_rsp_t *rsp = hsk_rs_queue_dequeue(ns->rs_queue);
-  while(rsp) {
-    hsk_rs_respond(ns, rsp->req, rsp->status, rsp->result);
-
-    hsk_dns_req_free(rsp->req);
-    ub_resolve_free(rsp->result);
-    free(rsp);
+  assert(ns);
 
-    rsp = hsk_rs_queue_dequeue(ns->rs_queue);
-  }
+  hsk_rs_respond(ns, req, status, result);
+  hsk_dns_req_free(req);
+  ub_resolve_free(result);
 }
 
 static void
 after_close(uv_handle_t *handle) {}
-
-static void
-after_close_free(uv_handle_t *handle) {
-  free(handle);
-}
-
-static void
-run_unbound_worker(void *arg) {
-  hsk_rs_t *ns = (hsk_rs_t *)arg;
-
-  while(ns->rs_worker_running) {
-    ub_wait(ns->ub);
-  }
-}
-
-static void
-after_resolve_shutdown(void *data, int status, struct ub_result *result) {
-  ub_resolve_free(result);
-
-  hsk_rs_t *ns = (hsk_rs_t *)data;
-
-  ns->rs_worker_running = false;
-}
diff --git a/src/rs.h b/src/rs.h
index 34128db..05dad72 100644
--- a/src/rs.h
+++ b/src/rs.h
@@ -8,34 +8,18 @@
 #include <unbound.h>
 
 #include "ec.h"
+#include "rs_worker.h"
 #include "uv.h"
 
 /*
  * Types
  */
 
-// Response data from libunbound - used to queue responses back to the libuv
-// event loop in a linked list
-typedef struct _hsk_rs_rsp_t {
-  struct _hsk_rs_rsp_t *next;
-  hsk_dns_req_t *req;
-  struct ub_result *result;
-  int status;
-} hsk_rs_rsp_t;
-
-typedef struct {
-  uv_mutex_t mutex;
-  hsk_rs_rsp_t *head;  // Oldest response
-  hsk_rs_rsp_t *tail;  // Newest response
-} hsk_rs_queue_t;
-
 typedef struct {
   uv_loop_t *loop;
   struct ub_ctx *ub;
   uv_udp_t socket;
-  hsk_rs_queue_t *rs_queue;
-  uv_async_t *rs_async;
-  uv_thread_t rs_worker;
+  hsk_rs_worker_t *rs_worker;
   hsk_ec_t *ec;
   char *config;
   struct sockaddr_storage stub_;
@@ -46,7 +30,6 @@ typedef struct {
   uint8_t read_buffer[4096];
   bool bound;
   bool receiving;
-  bool rs_worker_running;
 } hsk_rs_t;
 
 /*
diff --git a/src/rs_worker.c b/src/rs_worker.c
new file mode 100644
index 0000000..94d321b
--- /dev/null
+++ b/src/rs_worker.c
@@ -0,0 +1,347 @@
+#include "config.h"
+
+#include <assert.h>
+#include <stdint.h>
+#include <stdbool.h>
+#include <unbound.h>
+
+#include "dns.h"
+#include "error.h"
+#include "rs_worker.h"
+#include "uv.h"
+
+/*
+ * Prototypes
+ */
+static void
+hsk_rs_worker_log(hsk_rs_worker_t *ns, const char *fmt, ...);
+
+static void
+after_close_free(uv_handle_t *handle);
+
+static void
+run_unbound_worker(void *arg);
+
+static void
+after_resolve_shutdown(void *data, int status, struct ub_result *result);
+
+static void
+after_resolve_onthread(void *data, int status, struct ub_result *result);
+
+static void
+after_resolve_async(uv_async_t *async);
+
+/*
+ * Response Queue
+ */
+int
+hsk_rs_queue_init(hsk_rs_queue_t *queue) {
+  if (uv_mutex_init(&queue->mutex))
+    return HSK_EFAILURE;
+  queue->head = NULL;
+  queue->tail = NULL;
+
+  return HSK_SUCCESS;
+}
+
+void
+hsk_rs_queue_uninit(hsk_rs_queue_t *queue) {
+  hsk_rs_rsp_t *current = queue->head;
+  while (current) {
+    hsk_rs_rsp_t *next = current->next;
+    free(current);
+    current = next;
+  }
+
+  uv_mutex_destroy(&queue->mutex);
+}
+
+hsk_rs_queue_t *
+hsk_rs_queue_alloc() {
+  hsk_rs_queue_t *queue = malloc(sizeof(hsk_rs_queue_t));
+  if (!queue)
+    return NULL;
+
+  if (hsk_rs_queue_init(queue) != HSK_SUCCESS) {
+    free(queue);
+    return NULL;
+  }
+
+  return queue;
+}
+
+void
+hsk_rs_queue_free(hsk_rs_queue_t *queue) {
+  if(queue) {
+    hsk_rs_queue_uninit(queue);
+    free(queue);
+  }
+}
+
+// Dequeue the oldest queued response - thread-safe.
+// Returned object is now owned by the caller; returns nullptr if there is
+// nothing queued.
+hsk_rs_rsp_t *
+hsk_rs_queue_dequeue(hsk_rs_queue_t *queue) {
+  uv_mutex_lock(&queue->mutex);
+
+  hsk_rs_rsp_t *oldest = queue->head;
+  if (oldest) {
+    queue->head = oldest->next;
+    oldest->next = NULL;
+    // If this was the only queued request, clear tail too
+    if(queue->tail == oldest)
+      queue->tail = NULL;
+  }
+
+  uv_mutex_unlock(&queue->mutex);
+
+  return oldest;
+}
+
+// Enqueue a response - thread-safe.
+// The queue takes ownership of the response (until it's popped off again).
+void
+hsk_rs_queue_enqueue(hsk_rs_queue_t *queue, hsk_rs_rsp_t *rsp) {
+  uv_mutex_lock(&queue->mutex);
+
+  if (!queue->tail) {
+    // There were no requests queued; this one becomes head and tail
+    assert(!queue->head);   // Invariant - set and cleared together
+    queue->head = rsp;
+    queue->tail = rsp;
+  }
+  else {
+    // There are requests queued already, add this one to the tail
+    queue->tail->next = rsp;
+    queue->tail = rsp;
+  }
+
+  uv_mutex_unlock(&queue->mutex);
+}
+
+/*
+ * Response worker thread
+ */
+int
+hsk_rs_worker_init(hsk_rs_worker_t *worker, uv_loop_t *loop, struct ub_ctx *ub) {
+  if (!worker || !loop || !ub)
+    return HSK_EBADARGS;
+
+  worker->rs_queue = NULL;
+  worker->rs_async = NULL;
+  worker->ub = NULL;
+
+  worker->rs_queue = hsk_rs_queue_alloc();
+  if (!worker->rs_queue) {
+    hsk_rs_worker_log(worker, "failed to create response queue");
+    goto fail;
+  }
+
+  // Allocate this separately on the heap because uv_close() is asynchronous.
+  worker->rs_async = malloc(sizeof(uv_async_t));
+  if (!worker->rs_async) {
+    hsk_rs_worker_log(worker, "out of memory");
+    goto fail;
+  }
+
+  // Initialize the async and set data if successful.  (This also indicates to
+  // the cleanup logic that the async needs to be closed.)
+  worker->rs_async->data = NULL;
+  if (uv_async_init(loop, worker->rs_async, after_resolve_async)) {
+    hsk_rs_worker_log(worker, "failed to create libuv async event");
+    goto fail;
+  }
+  worker->rs_async->data = (void *)worker;
+
+  // Start the worker thread.  Set unbound context to indicate that the thread
+  // is running.  If it starts, we can no longer write worker->ub until we sync
+  // up both threads again in _uninit().
+  worker->ub = ub;
+  if (uv_thread_create(&worker->rs_thread, run_unbound_worker, (void *)worker)) {
+    hsk_rs_worker_log(worker, "failed to create libuv worker thread");
+    // Failed to start, not running.
+    worker->ub = NULL;
+    goto fail;
+  }
+
+  return HSK_SUCCESS;
+
+fail:
+  hsk_rs_worker_uninit(worker);
+
+  return HSK_EFAILURE;
+}
+
+void
+hsk_rs_worker_uninit(hsk_rs_worker_t *worker) {
+  // Note that _uninit() is also used to clean up a partially-constructed
+  // worker if _init() fails.
+
+  if (worker->ub) {
+    // We need to tell the libunbound worker to exit - wake up the thread and
+    // clear ub on that thread.
+    //
+    // libunbound doesn't give us a good way to do this, the only way is to
+    // issue a dummy query and do this in the callback on the worker thread.
+    //
+    // On Unix, we could poll unbound's file descriptor manually with another
+    // file descriptor to allow us to wake the thread another way.  On Windows
+    // though, libunbound does not provide any access to its WSAEVENT to do the
+    // same thing; there's no other way to do this.
+    int rc = ub_resolve_async(worker->ub, ".", HSK_DNS_NS, HSK_DNS_IN,
+                              (void *)worker, after_resolve_shutdown, NULL);
+    if (rc != 0)
+      hsk_rs_worker_log(worker, "cannot shut down worker thread: %s\n", ub_strerror(rc));
+    else
+      uv_thread_join(&worker->rs_thread);
+  }
+
+  if (worker->rs_async) {
+    // If it was also initialized, close it and free asynchronously
+    if (worker->rs_async->data) {
+      worker->rs_async->data = NULL;
+      uv_close((uv_handle_t *)worker->rs_async, after_close_free);
+      worker->rs_async = NULL;
+    }
+    else {
+      // Wasn't initialized, just free memory
+      free(worker->rs_async);
+      worker->rs_async = NULL;
+    }
+  }
+
+  if (worker->rs_queue) {
+    hsk_rs_queue_free(worker->rs_queue);
+    worker->rs_queue = NULL;
+  }
+}
+
+hsk_rs_worker_t *
+hsk_rs_worker_alloc(uv_loop_t *loop, struct ub_ctx *ub) {
+  hsk_rs_worker_t *worker = malloc(sizeof(hsk_rs_worker_t));
+  if (!worker)
+    return NULL;
+
+  if (hsk_rs_worker_init(worker, loop, ub) != HSK_SUCCESS) {
+    free(worker);
+    return NULL;
+  }
+
+  return worker;
+}
+
+void
+hsk_rs_worker_free(hsk_rs_worker_t *worker) {
+  if(worker) {
+    hsk_rs_worker_uninit(worker);
+    free(worker);
+  }
+}
+
+int
+hsk_rs_worker_resolve(hsk_rs_worker_t *worker, char *name, int rrtype,
+                      int rrclass, void *data, ub_callback_type callback) {
+  if (!callback)
+    return HSK_EBADARGS;
+
+  // Hold the callback data/func in a response object.  When the results come
+  // in, we'll fill in the rest of this object and add it to the result queue.
+  hsk_rs_rsp_t *rsp = malloc(sizeof(hsk_rs_rsp_t));
+  rsp->next = NULL;
+  rsp->cb_data = data;
+  rsp->cb_func = callback;
+  rsp->worker = worker;
+  rsp->status = 0;
+
+  int rc = ub_resolve_async(worker->ub, name, rrtype, rrclass, (void *)rsp,
+                            after_resolve_onthread, NULL);
+  if (rc) {
+    hsk_rs_worker_log(worker, "unbound error: %s\n", ub_strerror(rc));
+    return HSK_EFAILURE;
+  }
+
+  return HSK_SUCCESS;
+}
+
+static void
+hsk_rs_worker_log(hsk_rs_worker_t *worker, const char *fmt, ...) {
+  printf("rs_worker: ");
+
+  va_list args;
+  va_start(args, fmt);
+  vprintf(fmt, args);
+  va_end(args);
+}
+
+static void
+after_close_free(uv_handle_t *handle) {
+  free(handle);
+}
+
+static void
+run_unbound_worker(void *arg) {
+  hsk_rs_worker_t *worker = (hsk_rs_worker_t *)arg;
+
+  while(worker->ub) {
+    ub_wait(worker->ub);
+  }
+}
+
+static void
+after_resolve_shutdown(void *data, int status, struct ub_result *result) {
+  ub_resolve_free(result);
+
+  hsk_rs_worker_t *worker = (hsk_rs_worker_t *)data;
+
+  // Clear this to stop the worker event loop.  This is safe because we've
+  // synced up both threads to ensure they're not reading this - the main thread
+  // won't read it any more at all (it's just going to wait for the worker to
+  // exit with a _join()), and we're inside a ub_wait() on the worker thread.
+  worker->ub = NULL;
+}
+
+// Handle a resolve result on the libunbound worker thread, dispatch back to the
+// libuv event loop.
+static void
+after_resolve_onthread(void *data, int status, struct ub_result *result) {
+  hsk_rs_rsp_t *rsp = (hsk_rs_rsp_t *)data;
+  hsk_rs_worker_t *worker = rsp->worker;
+
+  rsp->result = result;
+  rsp->status = status;
+
+  // Enqueue the response.  This is safe to do on the worker thread:
+  // - The worker->rs_queue pointer is not modified after initialization until
+  //   the worker thread has been stopped
+  // - The hsk_rs_queue_t object itself is thread-safe
+  hsk_rs_queue_enqueue(worker->rs_queue, rsp);
+
+  // Queue an async event to process the response on the libuv event loop.
+  // Like rs_queue, the rs_async pointer is safe to use because it's not
+  // modified until the libunbound worker is stopped.
+  uv_async_send(worker->rs_async);
+}
+
+static void
+after_resolve_async(uv_async_t *async) {
+  hsk_rs_worker_t *worker = async->data;
+
+  // Since uv_close() is async, it might be possible to process this event after
+  // the worker is shut down but before the async is closed.
+  if(!worker)
+    return;
+
+  // Dequeue and process all events in the queue - libuv coalesces calls to
+  // uv_async_send().
+  hsk_rs_rsp_t *rsp = hsk_rs_queue_dequeue(worker->rs_queue);
+  while(rsp) {
+    rsp->cb_func(rsp->cb_data, rsp->status, rsp->result);
+
+    // Free the response element - the callback is responsible for the unbound
+    // result
+    free(rsp);
+
+    rsp = hsk_rs_queue_dequeue(worker->rs_queue);
+  }
+}
diff --git a/src/rs_worker.h b/src/rs_worker.h
new file mode 100644
index 0000000..3e4c16b
--- /dev/null
+++ b/src/rs_worker.h
@@ -0,0 +1,84 @@
+#ifndef _HSK_RS_WORKER_
+#define _HSK_RS_WORKER_
+
+#include <assert.h>
+#include <stdint.h>
+#include <stdbool.h>
+
+#include <unbound.h>
+
+#include "uv.h"
+
+/*
+ * Types
+ */
+
+struct _hsk_rs_rsp_t;
+typedef struct _hsk_rs_rsp_t hsk_rs_rsp_t;
+
+// Thread-safe response queue - synchronized with a mutex; responses enqueued
+// from worker thread and dequeued on libuv event loop thread.
+typedef struct {
+  uv_mutex_t mutex;
+  hsk_rs_rsp_t *head;  // Oldest response
+  hsk_rs_rsp_t *tail;  // Newest response
+} hsk_rs_queue_t;
+
+// Response worker thread - relays libunbound results from its worker thread to
+// the libuv event loop thread.
+typedef struct {
+  // Queue of results received from libunbound.
+  hsk_rs_queue_t *rs_queue;
+  // Async used to signal back to the libuv event loop.
+  uv_async_t *rs_async;
+  uv_thread_t rs_thread;
+  // The unbound context processed by the worker thread.  Indicates whether the
+  // worker thread event loop is running.
+  struct ub_ctx *ub;
+} hsk_rs_worker_t;
+
+// Response data from libunbound - used to queue responses back to the libuv
+// event loop in a linked list
+struct _hsk_rs_rsp_t {
+  hsk_rs_rsp_t *next;
+  // Callback and data given to hsk_rs_worker_resolve()
+  void *cb_data;
+  ub_callback_type cb_func;
+  union {
+    // Before the response is received, store a pointer back to the worker so we
+    // can enqueue the response.
+    hsk_rs_worker_t *worker;
+    // After the response is enqueued, store the result from libunbound
+    struct ub_result *result;
+  };
+  // Response status from libunbound
+  int status;
+};
+
+/*
+ * Response worker thread
+ */
+
+// Initialize with the libuv event loop where results are handled and the
+// libunbound context to process on the worker thread.  This starts the worker
+// thread.
+int
+hsk_rs_worker_init(hsk_rs_worker_t *worker, uv_loop_t *loop, struct ub_ctx *ub);
+
+void
+hsk_rs_worker_uninit(hsk_rs_worker_t *worker);
+
+hsk_rs_worker_t *
+hsk_rs_worker_alloc(uv_loop_t *loop, struct ub_ctx *ub);
+
+void
+hsk_rs_worker_free(hsk_rs_worker_t *worker);
+
+// Resolve a name.  The name, rrtype, and rrclass parameters are passed through
+// to libunbound.  The result callback occurs in the libuv event loop.  When the
+// callback occurs, ownership of the ub_result is passed to the callback.
+int
+hsk_rs_worker_resolve(hsk_rs_worker_t *worker, char *name, int rrtype,
+                      int rrclass, void *data, ub_callback_type callback);
+
+#endif
-- 
2.17.1

